{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b92ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "YKS Analiz Sistemi - Ana Notebook\n",
    "TÃ¼m modÃ¼llerin entegre kullanÄ±mÄ±\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 1: KÃ¼tÃ¼phaneleri Ä°Ã§e Aktar\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Kendi modÃ¼llerimizi iÃ§e aktar\n",
    "from data_loader import GoogleSheetsLoader\n",
    "from data_cleaner import DataCleaner\n",
    "from analysis.net_analyzer import NetAnalyzer\n",
    "from analysis.topic_analyzer import TopicAnalyzer\n",
    "from visualization.net_charts import NetVisualizer\n",
    "from visualization.topic_charts import TopicVisualizer\n",
    "from config import Config\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"âœ… TÃ¼m modÃ¼ller yÃ¼klendi!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a811da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: KonfigÃ¼rasyon AyarlarÄ±\n",
    "\n",
    "# .env dosyasÄ±nÄ± bu hÃ¼crede en baÅŸta yÃ¼kle\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# validate_config artÄ±k bir static method olduÄŸu iÃ§in bu ÅŸekilde Ã§aÄŸrÄ±labilir.\n",
    "Config.validate_config()\n",
    "\n",
    "# Ortam deÄŸiÅŸkenlerinden deÄŸerleri al\n",
    "SHEET_URL = os.getenv(\"GOOGLE_SHEET_URL\")\n",
    "CREDENTIALS_PATH = os.getenv(\"CREDENTIALS_PATH\")\n",
    "print(\"ðŸ“„ Google Sheets URL:\", SHEET_URL)\n",
    "print(\"ðŸ”‘ Credentials Path:\", CREDENTIALS_PATH)\n",
    "\n",
    "EXAM_TYPE = \"TYT\"\n",
    "TARGET_NET = config.Analysis.DEFAULT_TARGET_NET[EXAM_TYPE]\n",
    "\n",
    "print(f\"ðŸ“Š SÄ±nav TÃ¼rÃ¼: {EXAM_TYPE}\")\n",
    "print(f\"ðŸŽ¯ Hedef Net: {TARGET_NET}\")\n",
    "\n",
    "# loader'a ortam deÄŸiÅŸkenlerinden alÄ±nan deÄŸerleri ver\n",
    "loader = GoogleSheetsLoader(SHEET_URL, CREDENTIALS_PATH)\n",
    "cleaner = DataCleaner(config, strict_mode=False, auto_fix=True)\n",
    "net_analyzer = NetAnalyzer(config, exam_type=EXAM_TYPE)\n",
    "topic_analyzer = TopicAnalyzer(config, exam_type=EXAM_TYPE)\n",
    "net_viz = NetVisualizer(config)\n",
    "topic_viz = TopicVisualizer(config)\n",
    "\n",
    "print(\"\\nâœ… TÃ¼m ana nesneler yapÄ±landÄ±rma ile oluÅŸturuldu!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5992f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“¥ Veriler yÃ¼kleniyor...\")\n",
    "\n",
    "if EXAM_TYPE == \"TYT\":\n",
    "    raw_data = loader.load_tyt_data()\n",
    "else:\n",
    "    raw_data = loader.load_ayt_data()\n",
    "\n",
    "print(f\"âœ… {len(raw_data)} deneme yÃ¼klendi\")\n",
    "print(\"\\nðŸ“‹ YÃ¼klenen Ham Veriden Ä°lk 3 SatÄ±r:\")\n",
    "display(raw_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e886b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: Veri Temizleme\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nðŸ§¹ Veriler temizleniyor...\")\n",
    "\n",
    "# Temizleyici oluÅŸtur\n",
    "cleaner = DataCleaner(config, strict_mode=False, auto_fix=True)\n",
    "\n",
    "# Tam temizleme\n",
    "cleaned_data = cleaner.clean_full_dataset(raw_data, exam_type=EXAM_TYPE)\n",
    "\n",
    "# TÃ¼retilmiÅŸ Ã¶zellikler ekle\n",
    "cleaned_data = cleaner.add_derived_features(cleaned_data, exam_type=EXAM_TYPE)\n",
    "\n",
    "# Temizleme raporu\n",
    "report = cleaner.get_cleaning_report()\n",
    "print(f\"\\nðŸ“Š Temizleme Raporu:\")\n",
    "print(f\"  â€¢ Ã‡Ä±karÄ±lan satÄ±r: {report['rows_removed']}\")\n",
    "print(f\"  â€¢ DÃ¼zeltilen deÄŸer: {report['values_fixed']}\")\n",
    "print(f\"  â€¢ UyarÄ±lar: {len(report['warnings'])}\")\n",
    "\n",
    "print(f\"\\nâœ… Temizleme tamamlandÄ±: {len(cleaned_data)} deneme\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e9621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 5: Net Analizi\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nðŸ“Š Net analizi yapÄ±lÄ±yor...\")\n",
    "\n",
    "# Net analizÃ¶r oluÅŸtur\n",
    "net_analyzer = NetAnalyzer(config, exam_type=EXAM_TYPE)\n",
    "\n",
    "# Toplam net istatistikleri\n",
    "print(\"\\n=== TOPLAM NET Ä°STATÄ°STÄ°KLERÄ° ===\")\n",
    "total_stats = net_analyzer.calculate_statistics(cleaned_data, 'Toplam Net')\n",
    "for key, value in total_stats.items():\n",
    "    print(f\"  {key}: {value:.2f}\" if isinstance(value, float) else f\"  {key}: {value}\")\n",
    "\n",
    "# Trend analizi\n",
    "print(\"\\n=== TREND ANALÄ°ZÄ° ===\")\n",
    "trend = net_analyzer.get_progression_trend(cleaned_data, 'Toplam Net')\n",
    "print(f\"  Trend: {trend['trend']}\")\n",
    "print(f\"  EÄŸim: {trend['slope']:.2f} net/deneme\")\n",
    "print(f\"  RÂ²: {trend['r_squared']:.3f}\")\n",
    "print(f\"  Toplam Ä°lerleme: {trend['total_improvement']:.1f} net\")\n",
    "print(f\"  Sonraki Tahmin: {trend['next_prediction']:.1f} net\")\n",
    "\n",
    "# TÃ¼m dersler iÃ§in istatistikler\n",
    "print(\"\\n=== DERS BAZLI Ä°STATÄ°STÄ°KLER ===\")\n",
    "all_stats = net_analyzer.get_all_subjects_statistics(cleaned_data)\n",
    "print(all_stats[['mean', 'std', 'min', 'max']].round(2))\n",
    "\n",
    "# ZayÄ±f ve gÃ¼Ã§lÃ¼ dersler\n",
    "print(\"\\n=== ZAYIF DERSLER ===\")\n",
    "weak = net_analyzer.identify_weak_subjects(cleaned_data)\n",
    "for subject_info in weak[:3]:\n",
    "    print(f\"  â€¢ {subject_info['subject']}: {subject_info['mean']:.1f} net (Trend: {subject_info['trend']})\")\n",
    "\n",
    "print(\"\\n=== GÃœÃ‡LÃœ DERSLER ===\")\n",
    "strong = net_analyzer.identify_strong_subjects(cleaned_data)\n",
    "for subject_info in strong[:3]:\n",
    "    print(f\"  â€¢ {subject_info['subject']}: {subject_info['mean']:.1f} net (Trend: {subject_info['trend']})\")\n",
    "\n",
    "# Hedefe gÃ¶re durum\n",
    "print(\"\\n=== HEDEFE GÃ–RE DURUM ===\")\n",
    "target_comparison = net_analyzer.compare_to_target(cleaned_data, TARGET_NET)\n",
    "print(f\"  Hedef: {target_comparison['target']}\")\n",
    "print(f\"  Mevcut: {target_comparison['current']:.1f}\")\n",
    "print(f\"  Fark: {target_comparison['gap']:.1f} net\")\n",
    "print(f\"  Durum: {target_comparison['status']}\")\n",
    "if target_comparison['exams_needed']:\n",
    "    print(f\"  Tahmini Deneme SayÄ±sÄ±: {target_comparison['exams_needed']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd051fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: Konu Analizi\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nðŸ“š Konu analizi yapÄ±lÄ±yor...\")\n",
    "\n",
    "\n",
    "topic_analyzer = TopicAnalyzer(config, exam_type=EXAM_TYPE)\n",
    "# Ã–n hesaplama iÅŸlemi\n",
    "precomputed_topic_trends = topic_analyzer._precompute_all_topic_trends(cleaned_data)\n",
    "\n",
    "\n",
    "# En Ã§ok yanlÄ±ÅŸ yapÄ±lan konular\n",
    "print(\"\\n=== EN Ã‡OK YANLIÅž YAPILAN 10 KONU ===\")\n",
    "problematic = topic_analyzer.get_most_problematic_topics(cleaned_data, top_n=10)\n",
    "for i, (topic, count) in enumerate(problematic, 1):\n",
    "    print(f\"  {i}. {topic}: {count} kez\")\n",
    "\n",
    "# ZayÄ±f alanlar (ders bazlÄ±)\n",
    "print(\"\\n=== ZAYIF ALANLAR (DERS BAZLI) ===\")\n",
    "weak_areas = topic_analyzer.identify_weak_areas(cleaned_data, threshold=3)\n",
    "for subject, topics in weak_areas.items():\n",
    "    print(f\"\\n{subject}:\")\n",
    "    for topic in topics[:5]:  # Ä°lk 5 konu\n",
    "        print(f\"  â€¢ {topic}\")\n",
    "\n",
    "# Ã‡alÄ±ÅŸma planÄ± (DeÄŸiÅŸken adÄ± ve \"...\" hatasÄ± dÃ¼zeltildi)\n",
    "print(\"\\n=== Ã–NERÄ°LEN Ã‡ALIÅžMA PLANI ===\")\n",
    "study_plan = topic_analyzer.generate_study_plan(\n",
    "    cleaned_data, \n",
    "    precomputed_topic_trends, # DeÄŸiÅŸken adÄ± dÃ¼zeltildi\n",
    "    max_topics_per_subject=3\n",
    ")\n",
    "for subject, plan in study_plan.items():\n",
    "    print(f\"\\n{subject}:\")\n",
    "    for item in plan:\n",
    "        print(f\"  {item['sÄ±ra']}. {item['konu']}\")\n",
    "        print(f\"     Ã–ncelik: {item['Ã¶ncelik']} | Frekans: {item['frekans']} | {item['son_durum']}\")\n",
    "\n",
    "# Ders karÅŸÄ±laÅŸtÄ±rmasÄ±\n",
    "print(\"\\n=== DERS BAZLI KONU KARÅžILAÅžTIRMASI ===\")\n",
    "subject_comparison = topic_analyzer.compare_subjects_by_topics(cleaned_data)\n",
    "print(subject_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc7ce8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 7: Net Grafikleri\n",
    "# ============================================================================\n",
    "\n",
    "# Net Analiz SonuÃ§larÄ±\n",
    "all_net_stats = net_analyzer.get_all_subjects_statistics(cleaned_data)\n",
    "improvement_data = net_analyzer.calculate_improvement_rate(cleaned_data, window=3) # Veya config'den al\n",
    "\n",
    "# Konu Analiz SonuÃ§larÄ±\n",
    "most_problematic = topic_analyzer.get_most_problematic_topics(cleaned_data, top_n=15)\n",
    "subject_comparison_topics = topic_analyzer.compare_subjects_by_topics(cleaned_data)\n",
    "\n",
    "\n",
    "print(\"\\nðŸ“ˆ Net grafikleri oluÅŸturuluyor...\")\n",
    "\n",
    "# GÃ¶rselleÅŸtirici oluÅŸtur\n",
    "net_viz = NetVisualizer(config)\n",
    "\n",
    "# KlasÃ¶r oluÅŸtur\n",
    "charts_dir = Path(\"output/charts\")\n",
    "charts_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1. Toplam Net Trendi\n",
    "fig1 = net_viz.plot_total_nets_by_exam(\n",
    "    cleaned_data, \n",
    "    save_path=charts_dir / \"01_toplam_net.png\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# 2. TÃ¼m Derslerin KarÅŸÄ±laÅŸtÄ±rmasÄ± (Son Deneme)\n",
    "fig2 = net_viz.plot_all_subjects_comparison(\n",
    "    cleaned_data,\n",
    "    save_path=charts_dir / \"02_ders_karsilastirma.png\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "net_columns = [col for col in cleaned_data.columns if col.endswith('Net')]\n",
    "\n",
    "# 4. Ã‡ok Ã‡izgili KarÅŸÄ±laÅŸtÄ±rma\n",
    "fig4 = net_viz.plot_multi_subject_comparison(\n",
    "    cleaned_data,\n",
    "    net_columns[:4] if len(net_columns) >= 4 else net_columns,\n",
    "    save_path=charts_dir / \"04_coklu_karsilastirma.png\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Net grafikleri kaydedildi: {charts_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a2a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: Konu Grafikleri\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nðŸ“Š Konu grafikleri oluÅŸturuluyor...\")\n",
    "\n",
    "# Konu gÃ¶rselleÅŸtiricisi\n",
    "topic_viz = TopicVisualizer(config)\n",
    "\n",
    "# Son 3 deneme iÃ§in en Ã§ok yanlÄ±ÅŸ yapÄ±lan konular\n",
    "last3_data = cleaned_data.sort_values('Tarih').tail(3)\n",
    "problematic_last3 = topic_analyzer.get_most_problematic_topics(last3_data, top_n=15)\n",
    "\n",
    "fig8 = topic_viz.plot_total_wrong_topics(\n",
    "    problematic_topics=problematic_last3, \n",
    "    top_n=15,\n",
    "    save_path=charts_dir / \"08_en_cok_yanlis.png\",\n",
    ")\n",
    "plt.show()\n",
    "net_viz.dashboard(cleaned_data, exam_type=EXAM_TYPE)\n",
    "\n",
    "fig = topic_viz.plot_topic_trend_by_exam(cleaned_data, 'Matematik', 'tÃ¼rev')\n",
    "if fig:\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Grafik iÃ§in yeterli veri yok veya isimler eÅŸleÅŸmiyor.\")\n",
    "\n",
    "\n",
    "print(f\"âœ… Konu grafikleri kaydedildi: {charts_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cf58ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 9: Final Summary Report\n",
    "# ============================================================================\n",
    "\n",
    "# KapsamlÄ± rapor oluÅŸtur\n",
    "net_report = net_analyzer.generate_summary_report(cleaned_data)\n",
    "topic_report = topic_analyzer.generate_topic_summary_report(cleaned_data)\n",
    "\n",
    "print(f\"\\nðŸ“Š Genel Bilgiler:\")\n",
    "print(f\"  â€¢ SÄ±nav TÃ¼rÃ¼: {EXAM_TYPE}\")\n",
    "print(f\"  â€¢ Toplam Deneme SayÄ±sÄ±: {net_report.get('total_exams', 'N/A')}\")\n",
    "print(f\"  â€¢ Ã‡alÄ±ÅŸÄ±lan Tarih AralÄ±ÄŸÄ±: {net_report.get('date_range', {}).get('first', pd.NaT).strftime('%Y-%m-%d')} -> {net_report.get('date_range', {}).get('last', pd.NaT).strftime('%Y-%m-%d')}\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Net PerformansÄ±:\")\n",
    "print(f\"  â€¢ Ortalama Toplam Net: {net_report['overall_stats'].get('mean', 0):.2f}\")\n",
    "print(f\"  â€¢ En YÃ¼ksek Toplam Net: {net_report['overall_stats'].get('max', 0):.2f}\")\n",
    "print(f\"  â€¢ Son Deneme Toplam Net: {net_report['overall_stats'].get('latest', 0):.2f}\")\n",
    "print(f\"  â€¢ Ä°lerleme: {net_report['recent_improvement'].get('interpretation', 'N/A')}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Analiz tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37c2ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: Veriyi Kaydet (Opsiyonel)\n",
    "# ============================================================================\n",
    "\n",
    "# TemizlenmiÅŸ veriyi CSV olarak kaydet\n",
    "output_data_dir = Path(\"output/data\")\n",
    "output_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "cleaned_data.to_csv(output_data_dir / f\"{EXAM_TYPE}_temiz_veri.csv\", index=False)\n",
    "print(f\"\\nðŸ’¾ TemizlenmiÅŸ veri kaydedildi: {output_data_dir / f'{EXAM_TYPE}_temiz_veri.csv'}\")\n",
    "\n",
    "# Ã–zet raporlarÄ± JSON olarak kaydet\n",
    "import json\n",
    "\n",
    "with open(output_data_dir / f\"{EXAM_TYPE}_net_rapor.json\", 'w', encoding='utf-8') as f:\n",
    "    # DataFrame'leri dict'e Ã§evir\n",
    "    report_to_save = net_report.copy()\n",
    "    for key in report_to_save:\n",
    "        if isinstance(report_to_save[key], pd.DataFrame):\n",
    "            report_to_save[key] = report_to_save[key].to_dict()\n",
    "    json.dump(report_to_save, f, ensure_ascii=False, indent=2, default=str)\n",
    "\n",
    "print(f\"ðŸ’¾ Net raporu kaydedildi: {output_data_dir / f'{EXAM_TYPE}_net_rapor.json'}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ TÃ¼m iÅŸlemler tamamlandÄ±!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7bf271",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
